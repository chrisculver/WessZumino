{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from complexPyTorch.complexLayers import ComplexBatchNorm2d, ComplexConv2d, ComplexLinear\n",
    "from complexPyTorch.complexFunctions import complex_relu, complex_max_pool2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21.8%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "53.7%"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "100.0%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "train_set = datasets.MNIST('../data', train=True, transform=trans, download=True)\n",
    "test_set = datasets.MNIST('../data', train=False, transform=trans, download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size= batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size= batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComplexNet(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(ComplexNet, self).__init__()\n",
    "        self.conv1 = ComplexConv2d(1, 10, 5, 1)\n",
    "        self.bn  = ComplexBatchNorm2d(10)\n",
    "        self.conv2 = ComplexConv2d(10, 20, 5, 1)\n",
    "        self.fc1 = ComplexLinear(4*4*20, 500)\n",
    "        self.fc2 = ComplexLinear(500, 10)\n",
    "             \n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = self.bn(x)\n",
    "        x = self.conv2(x)\n",
    "        x = complex_relu(x)\n",
    "        x = complex_max_pool2d(x, 2, 2)\n",
    "        x = x.view(-1,4*4*20)\n",
    "        x = self.fc1(x)\n",
    "        x = complex_relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = x.abs()\n",
    "        x =  F.log_softmax(x, dim=1)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch:   0 [     0/ 60000 (  0%)]\tLoss: 2.378822\n",
      "Train Epoch:   0 [  6400/ 60000 ( 11%)]\tLoss: 0.218341\n",
      "Train Epoch:   0 [ 12800/ 60000 ( 21%)]\tLoss: 0.039315\n",
      "Train Epoch:   0 [ 19200/ 60000 ( 32%)]\tLoss: 0.042558\n",
      "Train Epoch:   0 [ 25600/ 60000 ( 43%)]\tLoss: 0.145385\n",
      "Train Epoch:   0 [ 32000/ 60000 ( 53%)]\tLoss: 0.059441\n",
      "Train Epoch:   0 [ 38400/ 60000 ( 64%)]\tLoss: 0.007106\n",
      "Train Epoch:   0 [ 44800/ 60000 ( 75%)]\tLoss: 0.015212\n",
      "Train Epoch:   0 [ 51200/ 60000 ( 85%)]\tLoss: 0.080821\n",
      "Train Epoch:   0 [ 57600/ 60000 ( 96%)]\tLoss: 0.053280\n",
      "Train Epoch:   1 [     0/ 60000 (  0%)]\tLoss: 0.021779\n",
      "Train Epoch:   1 [  6400/ 60000 ( 11%)]\tLoss: 0.009179\n",
      "Train Epoch:   1 [ 12800/ 60000 ( 21%)]\tLoss: 0.067152\n",
      "Train Epoch:   1 [ 19200/ 60000 ( 32%)]\tLoss: 0.127063\n",
      "Train Epoch:   1 [ 25600/ 60000 ( 43%)]\tLoss: 0.002395\n",
      "Train Epoch:   1 [ 32000/ 60000 ( 53%)]\tLoss: 0.006067\n",
      "Train Epoch:   1 [ 38400/ 60000 ( 64%)]\tLoss: 0.055754\n",
      "Train Epoch:   1 [ 44800/ 60000 ( 75%)]\tLoss: 0.018922\n",
      "Train Epoch:   1 [ 51200/ 60000 ( 85%)]\tLoss: 0.035062\n",
      "Train Epoch:   1 [ 57600/ 60000 ( 96%)]\tLoss: 0.013935\n",
      "Train Epoch:   2 [     0/ 60000 (  0%)]\tLoss: 0.023949\n",
      "Train Epoch:   2 [  6400/ 60000 ( 11%)]\tLoss: 0.015338\n",
      "Train Epoch:   2 [ 12800/ 60000 ( 21%)]\tLoss: 0.047620\n",
      "Train Epoch:   2 [ 19200/ 60000 ( 32%)]\tLoss: 0.003133\n",
      "Train Epoch:   2 [ 25600/ 60000 ( 43%)]\tLoss: 0.062658\n",
      "Train Epoch:   2 [ 32000/ 60000 ( 53%)]\tLoss: 0.131164\n",
      "Train Epoch:   2 [ 38400/ 60000 ( 64%)]\tLoss: 0.200756\n",
      "Train Epoch:   2 [ 44800/ 60000 ( 75%)]\tLoss: 0.001882\n",
      "Train Epoch:   2 [ 51200/ 60000 ( 85%)]\tLoss: 0.025954\n",
      "Train Epoch:   2 [ 57600/ 60000 ( 96%)]\tLoss: 0.015866\n",
      "Train Epoch:   3 [     0/ 60000 (  0%)]\tLoss: 0.000383\n",
      "Train Epoch:   3 [  6400/ 60000 ( 11%)]\tLoss: 0.007219\n",
      "Train Epoch:   3 [ 12800/ 60000 ( 21%)]\tLoss: 0.015082\n",
      "Train Epoch:   3 [ 19200/ 60000 ( 32%)]\tLoss: 0.004173\n",
      "Train Epoch:   3 [ 25600/ 60000 ( 43%)]\tLoss: 0.001438\n",
      "Train Epoch:   3 [ 32000/ 60000 ( 53%)]\tLoss: 0.019659\n",
      "Train Epoch:   3 [ 38400/ 60000 ( 64%)]\tLoss: 0.074603\n",
      "Train Epoch:   3 [ 44800/ 60000 ( 75%)]\tLoss: 0.001166\n",
      "Train Epoch:   3 [ 51200/ 60000 ( 85%)]\tLoss: 0.001863\n",
      "Train Epoch:   3 [ 57600/ 60000 ( 96%)]\tLoss: 0.002963\n",
      "Train Epoch:   4 [     0/ 60000 (  0%)]\tLoss: 0.008527\n",
      "Train Epoch:   4 [  6400/ 60000 ( 11%)]\tLoss: 0.036063\n",
      "Train Epoch:   4 [ 12800/ 60000 ( 21%)]\tLoss: 0.004175\n",
      "Train Epoch:   4 [ 19200/ 60000 ( 32%)]\tLoss: 0.000626\n",
      "Train Epoch:   4 [ 25600/ 60000 ( 43%)]\tLoss: 0.045960\n",
      "Train Epoch:   4 [ 32000/ 60000 ( 53%)]\tLoss: 0.002293\n",
      "Train Epoch:   4 [ 38400/ 60000 ( 64%)]\tLoss: 0.000627\n",
      "Train Epoch:   4 [ 44800/ 60000 ( 75%)]\tLoss: 0.001012\n",
      "Train Epoch:   4 [ 51200/ 60000 ( 85%)]\tLoss: 0.002818\n",
      "Train Epoch:   4 [ 57600/ 60000 ( 96%)]\tLoss: 0.000224\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = ComplexNet().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device).type(torch.complex64), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {:3} [{:6}/{:6} ({:3.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch,\n",
    "                batch_idx * len(data), \n",
    "                len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), \n",
    "                loss.item())\n",
    "            )\n",
    "\n",
    "# Run training on 50 epochs\n",
    "for epoch in range(5):\n",
    "    train(model, device, train_loader, optimizer, epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MachineLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
